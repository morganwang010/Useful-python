{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras imbalanced binary classification fraud RC",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0mUMFcYFUV1r"
      },
      "source": [
        "# Imbalanced classification: credit card fraud detection. RC edit\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/05/28<br>\n",
        "**Last modified:** 2020/04/17<br>\n",
        "**Description:** Demonstration of how to handle highly imbalanced classification problems -> use class_weight in fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UieF2A0SVTHQ",
        "colab_type": "text"
      },
      "source": [
        "https://keras.io/examples/structured_data/imbalanced_classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cSCZwsZNUV1t"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example looks at the\n",
        "[Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/)\n",
        "dataset to demonstrate how\n",
        "to train a classification model on data with highly imbalanced classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "De9T0HwIUV1u"
      },
      "source": [
        "## First, vectorize the CSV data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLRnlQMbVYRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3214c84e-8e4f-4e19-8f33-3605d9304501"
      },
      "source": [
        "ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creditcard.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AFvnPPK5UV1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a19a4759-666d-4851-93ca-9f665d2e8a8e"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "fname = \"creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1krydKDVycR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "99d4ce5c-ec72-4257-a169-04f77e8a5fe2"
      },
      "source": [
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "puLBmFknUV17"
      },
      "source": [
        "## Prepare a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D2_vS5LeUV19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4eccf469-ec64-4be3-e263-9101194b12ea"
      },
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "train_features = features[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_features = features[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(train_features))\n",
        "print(\"Number of validation samples:\", len(val_features))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_jdKe9hqgW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df346947-901e-46fb-fda3-1590f5d79a31"
      },
      "source": [
        "val_targets.sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6iHqO-jusfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "550882b6-1f51-4fc9-cd88-1e658f260dd7"
      },
      "source": [
        "100 * val_targets.sum() / len(val_targets)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13166903670932745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF4CT0eAuh0e",
        "colab_type": "text"
      },
      "source": [
        "75 fraudulant transactions in the val set, about 0.13%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPEZJQdKUV2E"
      },
      "source": [
        "## Analyze class imbalance in the targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YCDIc9YJUV2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cacb2d70-e021-4cf3-c8a5-923ca48af200"
      },
      "source": [
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2KUGcO4u0zv",
        "colab_type": "text"
      },
      "source": [
        "Pretty close % to validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L-16L18QUV2M"
      },
      "source": [
        "## Normalize the data using training set statistics\n",
        "Subtract mean and divide by SD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ZrWT1-vUV2N",
        "colab": {}
      },
      "source": [
        "mean = np.mean(train_features, axis=0)\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "std = np.std(train_features, axis=0)\n",
        "train_features /= std\n",
        "val_features /= std\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gamj8bvBUV2U"
      },
      "source": [
        "## Build a binary classification model\n",
        "https://keras.io/guides/sequential_model/\n",
        "\n",
        "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "86ayp1KrUV2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "fbb577ef-7139-4c54-9090-b71eb4c312b7"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(\n",
        "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
        "        ),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               7936      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 139,777\n",
            "Trainable params: 139,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fO3F92InUV2b"
      },
      "source": [
        "## Train the model with `class_weight` argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LQKo2G8yUV2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3732a717-53ca-4356-ecab-880652509a78"
      },
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    class_weight=class_weight,\n",
        ")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 1s - loss: 2.3824e-06 - fn: 49.0000 - fp: 24872.0000 - tn: 202557.0000 - tp: 368.0000 - precision: 0.0146 - recall: 0.8825 - val_loss: 0.1398 - val_fn: 8.0000 - val_fp: 1899.0000 - val_tn: 54987.0000 - val_tp: 67.0000 - val_precision: 0.0341 - val_recall: 0.8933\n",
            "Epoch 2/30\n",
            "112/112 - 1s - loss: 1.4327e-06 - fn: 34.0000 - fp: 6955.0000 - tn: 220474.0000 - tp: 383.0000 - precision: 0.0522 - recall: 0.9185 - val_loss: 0.1223 - val_fn: 6.0000 - val_fp: 2242.0000 - val_tn: 54644.0000 - val_tp: 69.0000 - val_precision: 0.0299 - val_recall: 0.9200\n",
            "Epoch 3/30\n",
            "112/112 - 1s - loss: 1.4953e-06 - fn: 30.0000 - fp: 8791.0000 - tn: 218638.0000 - tp: 387.0000 - precision: 0.0422 - recall: 0.9281 - val_loss: 0.0386 - val_fn: 10.0000 - val_fp: 363.0000 - val_tn: 56523.0000 - val_tp: 65.0000 - val_precision: 0.1519 - val_recall: 0.8667\n",
            "Epoch 4/30\n",
            "112/112 - 1s - loss: 1.4597e-06 - fn: 27.0000 - fp: 6234.0000 - tn: 221195.0000 - tp: 390.0000 - precision: 0.0589 - recall: 0.9353 - val_loss: 0.2886 - val_fn: 3.0000 - val_fp: 5400.0000 - val_tn: 51486.0000 - val_tp: 72.0000 - val_precision: 0.0132 - val_recall: 0.9600\n",
            "Epoch 5/30\n",
            "112/112 - 1s - loss: 1.1087e-06 - fn: 26.0000 - fp: 6984.0000 - tn: 220445.0000 - tp: 391.0000 - precision: 0.0530 - recall: 0.9376 - val_loss: 0.0673 - val_fn: 8.0000 - val_fp: 1100.0000 - val_tn: 55786.0000 - val_tp: 67.0000 - val_precision: 0.0574 - val_recall: 0.8933\n",
            "Epoch 6/30\n",
            "112/112 - 1s - loss: 8.3048e-07 - fn: 16.0000 - fp: 4823.0000 - tn: 222606.0000 - tp: 401.0000 - precision: 0.0768 - recall: 0.9616 - val_loss: 0.0409 - val_fn: 11.0000 - val_fp: 423.0000 - val_tn: 56463.0000 - val_tp: 64.0000 - val_precision: 0.1314 - val_recall: 0.8533\n",
            "Epoch 7/30\n",
            "112/112 - 1s - loss: 6.4022e-07 - fn: 16.0000 - fp: 4333.0000 - tn: 223096.0000 - tp: 401.0000 - precision: 0.0847 - recall: 0.9616 - val_loss: 0.0388 - val_fn: 9.0000 - val_fp: 788.0000 - val_tn: 56098.0000 - val_tp: 66.0000 - val_precision: 0.0773 - val_recall: 0.8800\n",
            "Epoch 8/30\n",
            "112/112 - 1s - loss: 8.8629e-07 - fn: 15.0000 - fp: 7214.0000 - tn: 220215.0000 - tp: 402.0000 - precision: 0.0528 - recall: 0.9640 - val_loss: 0.2168 - val_fn: 6.0000 - val_fp: 3984.0000 - val_tn: 52902.0000 - val_tp: 69.0000 - val_precision: 0.0170 - val_recall: 0.9200\n",
            "Epoch 9/30\n",
            "112/112 - 1s - loss: 8.0392e-07 - fn: 14.0000 - fp: 6663.0000 - tn: 220766.0000 - tp: 403.0000 - precision: 0.0570 - recall: 0.9664 - val_loss: 0.0812 - val_fn: 6.0000 - val_fp: 1665.0000 - val_tn: 55221.0000 - val_tp: 69.0000 - val_precision: 0.0398 - val_recall: 0.9200\n",
            "Epoch 10/30\n",
            "112/112 - 1s - loss: 8.9522e-07 - fn: 11.0000 - fp: 5156.0000 - tn: 222273.0000 - tp: 406.0000 - precision: 0.0730 - recall: 0.9736 - val_loss: 0.1245 - val_fn: 8.0000 - val_fp: 2733.0000 - val_tn: 54153.0000 - val_tp: 67.0000 - val_precision: 0.0239 - val_recall: 0.8933\n",
            "Epoch 11/30\n",
            "112/112 - 1s - loss: 6.3570e-07 - fn: 12.0000 - fp: 6758.0000 - tn: 220671.0000 - tp: 405.0000 - precision: 0.0565 - recall: 0.9712 - val_loss: 0.0566 - val_fn: 8.0000 - val_fp: 1306.0000 - val_tn: 55580.0000 - val_tp: 67.0000 - val_precision: 0.0488 - val_recall: 0.8933\n",
            "Epoch 12/30\n",
            "112/112 - 1s - loss: 5.7019e-07 - fn: 12.0000 - fp: 5167.0000 - tn: 222262.0000 - tp: 405.0000 - precision: 0.0727 - recall: 0.9712 - val_loss: 0.1441 - val_fn: 4.0000 - val_fp: 4064.0000 - val_tn: 52822.0000 - val_tp: 71.0000 - val_precision: 0.0172 - val_recall: 0.9467\n",
            "Epoch 13/30\n",
            "112/112 - 1s - loss: 3.9013e-07 - fn: 2.0000 - fp: 5115.0000 - tn: 222314.0000 - tp: 415.0000 - precision: 0.0750 - recall: 0.9952 - val_loss: 0.0694 - val_fn: 8.0000 - val_fp: 1966.0000 - val_tn: 54920.0000 - val_tp: 67.0000 - val_precision: 0.0330 - val_recall: 0.8933\n",
            "Epoch 14/30\n",
            "112/112 - 1s - loss: 3.2415e-07 - fn: 6.0000 - fp: 3167.0000 - tn: 224262.0000 - tp: 411.0000 - precision: 0.1149 - recall: 0.9856 - val_loss: 0.1320 - val_fn: 6.0000 - val_fp: 2099.0000 - val_tn: 54787.0000 - val_tp: 69.0000 - val_precision: 0.0318 - val_recall: 0.9200\n",
            "Epoch 15/30\n",
            "112/112 - 1s - loss: 5.7675e-07 - fn: 8.0000 - fp: 6843.0000 - tn: 220586.0000 - tp: 409.0000 - precision: 0.0564 - recall: 0.9808 - val_loss: 0.0786 - val_fn: 6.0000 - val_fp: 2438.0000 - val_tn: 54448.0000 - val_tp: 69.0000 - val_precision: 0.0275 - val_recall: 0.9200\n",
            "Epoch 16/30\n",
            "112/112 - 1s - loss: 3.9877e-07 - fn: 4.0000 - fp: 5809.0000 - tn: 221620.0000 - tp: 413.0000 - precision: 0.0664 - recall: 0.9904 - val_loss: 0.0492 - val_fn: 9.0000 - val_fp: 1053.0000 - val_tn: 55833.0000 - val_tp: 66.0000 - val_precision: 0.0590 - val_recall: 0.8800\n",
            "Epoch 17/30\n",
            "112/112 - 1s - loss: 3.6226e-07 - fn: 5.0000 - fp: 4278.0000 - tn: 223151.0000 - tp: 412.0000 - precision: 0.0878 - recall: 0.9880 - val_loss: 0.0596 - val_fn: 8.0000 - val_fp: 1166.0000 - val_tn: 55720.0000 - val_tp: 67.0000 - val_precision: 0.0543 - val_recall: 0.8933\n",
            "Epoch 18/30\n",
            "112/112 - 1s - loss: 5.5862e-07 - fn: 5.0000 - fp: 6888.0000 - tn: 220541.0000 - tp: 412.0000 - precision: 0.0564 - recall: 0.9880 - val_loss: 0.0151 - val_fn: 9.0000 - val_fp: 277.0000 - val_tn: 56609.0000 - val_tp: 66.0000 - val_precision: 0.1924 - val_recall: 0.8800\n",
            "Epoch 19/30\n",
            "112/112 - 1s - loss: 4.0885e-07 - fn: 6.0000 - fp: 5066.0000 - tn: 222363.0000 - tp: 411.0000 - precision: 0.0750 - recall: 0.9856 - val_loss: 0.0898 - val_fn: 10.0000 - val_fp: 1690.0000 - val_tn: 55196.0000 - val_tp: 65.0000 - val_precision: 0.0370 - val_recall: 0.8667\n",
            "Epoch 20/30\n",
            "112/112 - 1s - loss: 3.2337e-07 - fn: 1.0000 - fp: 3941.0000 - tn: 223488.0000 - tp: 416.0000 - precision: 0.0955 - recall: 0.9976 - val_loss: 0.0116 - val_fn: 12.0000 - val_fp: 234.0000 - val_tn: 56652.0000 - val_tp: 63.0000 - val_precision: 0.2121 - val_recall: 0.8400\n",
            "Epoch 21/30\n",
            "112/112 - 1s - loss: 1.8602e-07 - fn: 1.0000 - fp: 2090.0000 - tn: 225339.0000 - tp: 416.0000 - precision: 0.1660 - recall: 0.9976 - val_loss: 0.0064 - val_fn: 14.0000 - val_fp: 92.0000 - val_tn: 56794.0000 - val_tp: 61.0000 - val_precision: 0.3987 - val_recall: 0.8133\n",
            "Epoch 22/30\n",
            "112/112 - 1s - loss: 2.1654e-07 - fn: 2.0000 - fp: 2343.0000 - tn: 225086.0000 - tp: 415.0000 - precision: 0.1505 - recall: 0.9952 - val_loss: 0.0299 - val_fn: 10.0000 - val_fp: 529.0000 - val_tn: 56357.0000 - val_tp: 65.0000 - val_precision: 0.1094 - val_recall: 0.8667\n",
            "Epoch 23/30\n",
            "112/112 - 1s - loss: 2.1963e-07 - fn: 1.0000 - fp: 2921.0000 - tn: 224508.0000 - tp: 416.0000 - precision: 0.1247 - recall: 0.9976 - val_loss: 0.0715 - val_fn: 7.0000 - val_fp: 1406.0000 - val_tn: 55480.0000 - val_tp: 68.0000 - val_precision: 0.0461 - val_recall: 0.9067\n",
            "Epoch 24/30\n",
            "112/112 - 1s - loss: 4.0632e-07 - fn: 4.0000 - fp: 4361.0000 - tn: 223068.0000 - tp: 413.0000 - precision: 0.0865 - recall: 0.9904 - val_loss: 0.0674 - val_fn: 8.0000 - val_fp: 802.0000 - val_tn: 56084.0000 - val_tp: 67.0000 - val_precision: 0.0771 - val_recall: 0.8933\n",
            "Epoch 25/30\n",
            "112/112 - 1s - loss: 4.5153e-07 - fn: 5.0000 - fp: 3918.0000 - tn: 223511.0000 - tp: 412.0000 - precision: 0.0952 - recall: 0.9880 - val_loss: 0.0737 - val_fn: 12.0000 - val_fp: 496.0000 - val_tn: 56390.0000 - val_tp: 63.0000 - val_precision: 0.1127 - val_recall: 0.8400\n",
            "Epoch 26/30\n",
            "112/112 - 1s - loss: 2.1412e-06 - fn: 9.0000 - fp: 4634.0000 - tn: 222795.0000 - tp: 408.0000 - precision: 0.0809 - recall: 0.9784 - val_loss: 0.9171 - val_fn: 9.0000 - val_fp: 1206.0000 - val_tn: 55680.0000 - val_tp: 66.0000 - val_precision: 0.0519 - val_recall: 0.8800\n",
            "Epoch 27/30\n",
            "112/112 - 1s - loss: 2.3515e-06 - fn: 19.0000 - fp: 8592.0000 - tn: 218837.0000 - tp: 398.0000 - precision: 0.0443 - recall: 0.9544 - val_loss: 0.0318 - val_fn: 9.0000 - val_fp: 563.0000 - val_tn: 56323.0000 - val_tp: 66.0000 - val_precision: 0.1049 - val_recall: 0.8800\n",
            "Epoch 28/30\n",
            "112/112 - 1s - loss: 1.0210e-06 - fn: 10.0000 - fp: 4766.0000 - tn: 222663.0000 - tp: 407.0000 - precision: 0.0787 - recall: 0.9760 - val_loss: 0.0261 - val_fn: 12.0000 - val_fp: 170.0000 - val_tn: 56716.0000 - val_tp: 63.0000 - val_precision: 0.2704 - val_recall: 0.8400\n",
            "Epoch 29/30\n",
            "112/112 - 1s - loss: 1.3798e-06 - fn: 5.0000 - fp: 3599.0000 - tn: 223830.0000 - tp: 412.0000 - precision: 0.1027 - recall: 0.9880 - val_loss: 0.0837 - val_fn: 9.0000 - val_fp: 436.0000 - val_tn: 56450.0000 - val_tp: 66.0000 - val_precision: 0.1315 - val_recall: 0.8800\n",
            "Epoch 30/30\n",
            "112/112 - 1s - loss: 4.2126e-06 - fn: 15.0000 - fp: 5186.0000 - tn: 222243.0000 - tp: 402.0000 - precision: 0.0719 - recall: 0.9640 - val_loss: 0.0572 - val_fn: 10.0000 - val_fp: 850.0000 - val_tn: 56036.0000 - val_tp: 65.0000 - val_precision: 0.0710 - val_recall: 0.8667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6850093ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQMxVP85ZaWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(val_features)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_iSi5xs385",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68b8dfc3-f4d6-4a95-b046-7fdc5f4a243a"
      },
      "source": [
        "len(val_features)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56961"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOWOfLZNvThn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4aa0503b-d071-4cfc-c2d9-d62fdf5b6007"
      },
      "source": [
        "def calc_precision(tp, fp):\n",
        "  return tp / (tp + fp)\n",
        "\n",
        "def calc_recall(tp, fn):\n",
        "  return tp / (tp + fn)\n",
        "\n",
        "print(calc_precision(tp=402, fp=5186))\n",
        "\n",
        "print(calc_recall(tp=402, fn=15))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07193987115246958\n",
            "0.9640287769784173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3nzTqGdBUV2l"
      },
      "source": [
        "Final step\n",
        "112/112 - 1s - \n",
        "loss: 4.2126e-06 - \n",
        "\n",
        "* fn: 15.0000\n",
        "* fp: 5186.0000\n",
        "* tn: 222243.0000\n",
        "* tp: 402.0000\n",
        "* precision: 0.0719\n",
        "* recall: 0.9640\n",
        "\n",
        "\n",
        "* val_loss: 0.0572\n",
        "* val_fn: 10.0000 - Missing 10 fraudulent transactions\n",
        "* val_fp: 850.0000 - incorrectly flagging 850 legitimate transactions\n",
        "* val_tn: 56036.0000\n",
        "* val_tp: 65.0000 - Correctly identifying 65 of them as fraudulent\n",
        "* val_precision: 0.0710\n",
        "* val_recall: 0.8667\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "- Correctly identifying 65 of them as fraudulent\n",
        "- Missing 10 fraudulent transactions\n",
        "- At the cost of incorrectly flagging 850 legitimate transactions\n",
        "\n",
        "In the real world, one would put an even higher weight on class 1,\n",
        "so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets  declined in an online purchase -- this is why."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rbokHxRuIJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}